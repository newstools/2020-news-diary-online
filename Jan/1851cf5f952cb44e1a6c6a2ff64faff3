By Y. Z. Ya’u | 09 January 2020 The 14th Internet Governance Forum (IGF),
which was held in Berlin, Germany from 25 to 29 November 2019, had the
contestable theme of “One World. One Net. One Vision”. Not that MacBride of Many Voices, One World fame
would have raised an eyebrow about it, but in a world that is divided
along different patches with different development problems and
different goals, it is presumptuous to think that such a collection of
nations will have the same vision and voice. How could there be one
world when a divided world is our lived experience? How could the world
in which different actors have different access to power, means of
communication, wealth, etc. have the same voice? Even at practical
level, the internet is not just one net. With many countries erecting
different firewalls around the net or even Russia that has been testing
its own internet within Russia, it is clear we cannot be talking about
one net. How can the low speed of the world wide wait of a rural village
in Nigeria be the same net as the high speed broadband of Berlin? As
for one vision, that is a fairy tale: how can the vision of the
developing countries of the South be the same as the industrialised
North, unless we are being told that narrative that the development
trajectory must follow the same path of that of the industrial
countries. If there was no debate on this, it was not because everyone had
accepted this, but it is the practice that the theme of the IGF is
decided long before meeting through a filtering process that ensures
that dominant ideas carry the day. Anyway, “theme” is actually a wrong
word to use because there is no theme as such for the IGF. The diverse
issues, problems, solutions and experience sharing are too eclectic to
fit into a unifying theme. But while there was no debate about the problematically crafted
“theme” that brought us, there was no shortage of it in the various
panels and topics that featured at the Forum. One of the most
contentious of the topics was artificial intelligence (AI). With its
seeming apolitical nature, it is in reality the Trojan horse of
political interests. Having maintained a more than passing interest in
AI after teaching it as part of a course unit many years ago at Bayero
University, Kano, it was not surprising that it attracted my attention
at the IGF. But AI really took centre stage right from the beginning. On day zero, there was a panel on “AI in Africa – Between Ethical Challenges and Technical Opportunities”.
You could be right to ask, why Africa? Were the framers of the topic
drawing a narrative that essentialises Africa, or did they have in mind
that AI will have entirely different ramifications in Africa than the
whole of the world? My key takeaway point from the panel was first, the
submission that many designs of technology assistants tend to follow a
gender narrative that can be offensive to gender justice. With digital
personal assistants patterned and made to speak like women and also to
be extremely submissive, with no agency for question, it seems to seek
to reinforce the narrative that the place of women is in the caregiving
sector. In the context of gender digital inclusion, no doubt this could
provoke a debate and it did. The other takeaway was the naivety of some
of the panellists that improving access and skills was the key to
solving the problem of digital marginalisation of women. While access
and skills are clearly important, they are not sufficient and necessary
conditions for ending digital marginalisation of women. Access itself is
not just about a problem of differentials, but when technology is
called upon to normalise existing gender inequalities by either making
women not use the internet or when they fear it and thereby miss its
liberating ethos, we have to look elsewhere for a more nuanced
understanding of the basis for gender digital inclusion. Which is that
we need to understand the way social norms determine how women engage
technology and how patriarchy itself shapes both the perception and
insertion of technology in society. In the end, the debate was less about Africa than about women. That
is not to say that there were no issues of germane concern to Africa.
For instance, how will Africa leverage AI to address its development
problems? What can it do to speed up its catching-up game to be at the
centre and not periphery of AI development and application? Will AI not
reinforce the existing inequalities as well create a new division of
labour, with the North producing knowledge while the global South is
made to trade physical labour and its privacy as its data is outside its
control? But AI kept popping up every day and virtually in every panel, the
reason being that AI is assuming a new transformative force of its own.
As the debates unfolded in various panels and sessions, a number of
important questions were being asked about AI. First and foremost, there
is the proposition that it will lead to job losses. While proponents
and champions of AI argue that it will only be resulting in displacement
and creation of new jobs, other people think this argument has no basis
in either reality or logic. The reality is that every deployment of AI
application is resulting in massive job losses. Deploying intelligent
robots has made Amazon cut jobs. A story was told about a smart toilet
project in India which has thrown thousands of workers who earned their
livelihood cleaning toilets out of jobs. While we could frown at toilet
cleaning as not a decent job, the fact is that these smart toilets have
not created the new jobs that could absorb those who have lost their
jobs. In our quest for AI systems, how are we striking a balance between
ethical issues and rational economic calculation? AI seems to be driven
by a concern for efficiency in all its ramifications, but what will it
say about our humanity? We find contentment not just from the
materialisation of our economic rational calculation, but also about our
fears, emotions, love, etc. As we become more deeply dependent on
AI-embedded systems, would our humanity not be redefined to those
aspects that lend themselves to a line that is easy for algorithms to
make decisions? Will we still be able to make decisions on what matters
to us, or will AI-based systems take control of our lives? There is the not too small matter of how AI will impact and redefine
electoral politics and democracy in general. We are already seeing how
data, obtained without the consent and knowledge of the data subjects,
is being turned into a political capital. Bots are taking over the
communication space, often with vile messages; how can we be sure that
AI would not take over the political space, take over political
messaging and probably even from a deep profiling of citizens, decide to
vote and elect governments for us on our behalf? After all, AI is to
relieve us from burden, such as the efforts we put into voting. AI is controversial for many reasons, not just for killing jobs. As
it is predicated upon the extraction and use of massive amounts of data,
it portends the possibility of increased threats to privacy, misuse of
data, increasing surveillance by governments on citizens and elevated
levels of profiling. Discrimination can become insidious as algorithms
can be used to discriminate against certain profiles such as the poor,
immigrants, etc. AI was of course not the only controversial and contentious topic in
the IGF. Virtually every topic turned out to be more complex than the
proponents thought them to be. Take, for instance, the panel on digital
trade. This topic runs into difficulty right at the beginning as to what
constitutes digital trade. Was it e-commerce? Was it trade on the
cyberspace or was it trade in the means of the cyberspace? For the
“third world”, a key concern is where do we place trade on domain names,
bandwidth, domain hosting, all of which constitute capital flight out
of these countries to the developed countries because of poor
infrastructure in developing countries? Africa, for instance, is not
trading data (which is part of the spectrum of tradeable digitals)
because our data is held outside the continent and in the countries of
private sectors of the developed countries for which Africa does not get
paid. We have no control over how this data is used, by who and for
what purposes. What rules govern this trade? What are the safeguards
against human rights abuse? How do we mainstream social justice into it?
This has become even more, much more serious with the increasing
practice of placing backdoors by equipment manufacturers and
applications developers. Harmful content which seems to be seen negatively by all is another
controversial topic. How do we deal with such content online? Do we
surrender and look up to AI for solutions? Or do we allow platform
providers to censor us? There is an increasing realisation that both
government regulation and self-regulation have failed, and the push at
one of the panels was for multistakeholder regulation. The catch in this
is: how does such regulation work out in practice, with stakeholders
coming with different interests and concerns and with differing
conceptions of harmful content? And all this in the context of 
differentials in the distribution of power and resources. Nowhere was the concept of multistakeholder regulation pushed as in the “NRIs Collaborative Session on Cybersecurity”
in which I served as a panellist. We listened to experiences from
different countries and clearly governments and citizens do not speak
about the same harmful content. While there may be some intersections,
the differences are wide; governments think about regime survival and
regime protection as the problem of security, and therefore anything
that upsets this is harmful content. Citizens value their freedom and
their ability to express themselves and create a strong voice of their
own. Commercial interest wants to maximise profits and harmful content
is that which would drive profit down. Shutdowns as experienced in a
number of countries are the most extreme response to “harmful”. It hurts
commercial interests, deprives citizens of the ability to communicate
and use the internet for other important purposes such as learning and
livelihood, while it constrains the effectiveness of governments in
reaching out to their constituencies, yet in spite of all this, many
governments are willing to take that path of dealing with “harmful”
content. The recent attempt to legislate two different pieces of legislation
in Nigeria is an example of how different actors view the problem. The
government has proposed the two dangerous legislative pieces to deal
with “harmful” content but clearly it aims at stifling the effective use
of social media by citizens. One piece proposed the death penalty for
hate speech. While there is global consensus that hate speech is
negative, divisive and discriminatory and capable of provoking violence,
legislation has so far failed in dealing with it. But as in many other
countries, the proponents of the bill in Nigeria do not even have a
clear definition of what constitutes hate speech. The pre-eminence of AI at the 2019 IGF was further consolidated by the launch of the 2019 Global Information Society Watch (GISWatch) report
focused on AI. GISWatch, which is an annual report produced by the
Association for Progressive Communications (APC), each year takes a
specific topical theme for the report, and researchers and
activists/campaigners are commissioned to write on the different
ramifications of the theme from their country/regional contexts as well
as on a thematic basis. The 2019 report, produced in partnership with
ARTICLE 19, was entitled “Artificial intelligence: Human rights, social
justice and development”, and comprises a thematic section covering
various ramifications of AI, 40 country reports and three regional
reports. It was as if the report had anticipated the prominence and the
nature of the debate that could ensue at the IGF around AI. Both the
thematic section and the country/regional reports were written from the
lenses of global South perspectives, to address the imbalances in the
discourse which tended to focus more on the North. Even from the
perspective of its functioning, there is evidence that AI-based facial
recognition systems are failing to recognise black people because the
algorithms are fed and trained with data from Western faces. There is no doubt that AI will change the way we do many things and
improve efficiency and possibly reduce resource consumption. But on its
own, it will not promote a just world. Algorithm designers often think
that what they are doing is value-free and therefore AI is politically
neutral. That is a myth. Many such myths around technology abound. It is
to the credit of the organisers of the 14th IGF that they decided to
demystify some of these myths through a book that was shared to the
participants at registration. The book is entitled “Busted! The Truth
About the 50 Most Common Myths About the Internet”. In this collection
of essays, the editors picked 50 of these myths and showed them to not
be true. One of these ideas that was busted was the idea that algorithm
designers carry out their trade with value-free detachment. The debate around AI illustrates one of the weaknesses of the IGF.
Governments and intergovernmental agencies as decision makers at best
watch, but more often abstain from engaging in the IGF. But this is not
the only problem. With decision makers out of the room, two sets of
people who are equally passionate about what they know and love to do
are left to do the talking. The technical community speaks glowingly
about the promise of the transformative power of the technology,
especially as embedded by AI, but they are poor in understanding the
social issues grounded and impacted by their invention. On the other
hand, there are the passionate advocates, civil society activists,
experts in policy analysis but who often have poor technical knowledge.
The two often talk across each other, hardly listening to and rarely
understanding each other, and because the IGF is not a resolution
platform, no one cares if they are able to reach any consensus or not. Luckily, APC is an intersection of the two worlds. With its earlier
origins as a platform for alternative ISPs, it has deep-rooted technical
capital, but as a global advocacy group, it also understands the policy
terrain and the social grounding and implications of policies. Its
participation is connecting a movement across the divides. Nowhere was
this more evident than in the growing number of delegates who turned up
for the Discotech,
an annual side event organised by APC where techies and social
activists talk about what they do and understand with good background
music and food. This year, among the events of the IGF, it could have
been voted as the most popular item that attracted the most diverse
range of delegates. Confirming the role of APC as a valuable contributor to a more nuanced conversation in the IGF process was the announcement by the UN Secretary-General of the designation of former APC executive director and current APC consultant, Ms. Anriette Esterhuysen, as the new chair of the Internet Governance Forum’s Multistakeholder Advisory Group (MAG). With her experience in civil society, deeply grounded activism and high degree of knowledge about technical issues, her leadership of the MAG should be a beginning in turning the IGF into intelligible mutual dialogue among the different components so as to achieve better outcomes. Y. Z. Ya’u is the executive director of the Centre for Information Technology and Development (CITAD), an APC member organisation in Nigeria that is committed to the use of information and communication technologies (ICTs) for development and promotion of good governance. He attended the IGF 2019 in Berlin with the support of the APC Member Exchange and Travel Fund (METF). Article culled from apc.org